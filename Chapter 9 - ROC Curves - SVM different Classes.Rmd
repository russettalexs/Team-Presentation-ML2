---
title: "Chapter 9 - ROC Curves - SVM different Classes"
output: html_document
---
---
title: "Machine Learning Presentation 1 - Team 7"
output: html_document
---

```{r}
rm(list=ls())
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Make sure you install the e11071 and ROCR packages

*Table of Contents*
 - 9.6.3 ROC Curves
 - 9.6.4 SVM with Multiple Classes 
 - Applied Exercise 

```{r}
library(e1071)
```

We first generate some data with a non-linear class boundary, as follows:
```{r}
set.seed (1)
x=matrix(rnorm (200*2) , ncol =2)
x[1:100,]=x[1:100,]+2
x[101:150,]= x[101:150,] -2
y=c(rep(1 ,150),rep(2 ,50))
dat=data.frame(x=x,y=as.factor (y))
```

Plotting the data makes it clear that the class boundary is indeed nonlinear:
```{r}
plot(x, col=y)
```


The data is randomly split into training and testing groups. We then fit
the training data using the svm() function with a radial kernel and γ = 1:
```{r}
train=sample (200 ,100)
svmfit=svm(y~., data=dat [train ,], kernel ="radial", gamma=1, cost=1)
```


```{r}
plot(svmfit , dat[train ,])
```
The plot shows that the resulting SVM has a decidedly non-linear
boundary. 


The summary() function can be used to obtain some
information about the SVM fit:
```{r}
summary(svmfit)
```
We can see from the figure that there are a fair number of training errors in this SVM fit. 

If we increase the value of cost, we can reduce the number of training errors. However, this comes at the price of a more irregular decision boundary that seems to be at risk of overfitting the data. 



```{r}
svmfit= svm(y~., data=dat [train ,], kernel ="radial",gamma =1,
cost=1e5)
plot(svmfit ,dat [train ,])
```

We can perform cross-validation using tune() to select the best choice of γ and cost for an SVM with a radial kernel:

```{r}
set.seed(1)

tune.out=tune(svm , y~., data=dat[train ,], kernel ="radial",
ranges =list(cost=c(0.1 ,1 ,10 ,100 ,1000),
gamma=c(0.5,1,2,3,4)))

summary (tune.out)
```

Therefore, the best choice of parameters involves cost=1 and gamma=1. We
can view the test set predictions for this model by applying the predict() function to the data. Notice that to do this we subset the dataframe dat using -train as an index set.



```{r}
table(true=dat[-train ,"y"], pred=predict (tune.out$best.model ,
newdata =dat[-train ,]))
```
10% of test observations are misclassified by this SVM.

```{r}
library(ROCR)
library(gplots)
```

We first write a short function to plot an ROC curve
given a vector containing a numerical score for each observation, pred, and a vector containing the class label for each observation, truth.
```{r}
rocplot = function(pred , truth , ...){
predob = prediction (pred , truth)
perf = performance (predob , "tpr ", "fpr ")
plot(perf ,...)}
```




```{r}
svmfit.opt= svm(y~., data=dat[train ,], kernel ="radial", gamma =2, cost=1, decision.values=TRUE)

fitted= attributes(predict(svmfit.opt ,dat[train ,], decision.values=TRUE))$decision.values
```

Now we can produce the ROC plot.



```{r}
par(mfrow = c(1,2))
# rocplot(fitted, dat[train, "y"], main = "Training Data")

```



```{r}
svmfit.flex=svm (y~., data=dat[train ,], kernel ="radial",
gamma =50, cost=1, decision.values =T)

fitted=attributes(predict(svmfit.flex ,dat[train ,], decision.values =T))$decision.values

# rocplot (fitted ,dat [train ,"y"], add =T,col ="red ")
```

However, these ROC curves are all on the training data. We are really
more interested in the level of prediction accuracy on the test data. When
we compute the ROC curves on the test data, the model with γ = 2 appears
to provide the most accurate results.


```{r}
fitted=attributes(predict(svmfit.opt ,dat[-train ,], decision.values =T))$decision.values

# rocplot (fitted ,dat [-train ,"y"], main ="Test Data")

fitted =attributes(predict(svmfit.flex ,dat[-train ,], decision.values=T))$decision.values

# rocplot (fitted ,dat [-train ,"y"], add=T,col =" red ")
```









## SVM with Multiple Classes

If the response is a factor containing more than two levels, then the svm()
function will perform multi-class classification using the one-versus-one approach. We explore that setting here by generating a third class of observations.

```{r}
# rm(list=ls())
```


```{r cars}
library(e1071)

set.seed(1)
x=rbind(x, matrix(rnorm (50*2) , ncol=2))
y=c(y, rep(0,50))
x[y==0,2]= x[y==0 ,2]+2
dat=data.frame(x=x, y=as.factor(y))
par(mfrow=c(1,1))
plot(x,col=(y+1))

svmfit=svm(y~., data=dat , kernel ="radial", cost=10, gamma =1)
plot(svmfit , dat)
```

Radial kernel support vector machine is a good approach when the data is not linearly separable. A cost argument allows us to specify the cost of a violation to the margin. When the cost argument is small, then the margins will be wide and many support vectors will be on the margin or will violate the margin. the gamma parameter defines how far the influence of a single training example reaches, with low values meaning 'far' and high values meaning 'close'

```{r}
svmfit=svm(y~., data=dat , kernel ="radial", cost=10, gamma =1)
plot(svmfit , dat)
```

The e1071 library can also be used to perform support vector regression,
if the response vector that is passed in to svm() is numerical rather than a
factor.


